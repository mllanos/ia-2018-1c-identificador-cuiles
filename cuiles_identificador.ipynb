{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP N° 2\n",
    "## Obteniendo un posible CUIT a partir de una fecha de nacimiento y género"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Libreria para tratar con Arrays y otro tipos de datos utilizados\n",
    "import numpy as np\n",
    "#Libreria para graficar\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#Libreria que probee herramientas para el manejo de datos\n",
    "import pandas as pd\n",
    "#Libreria que incluye redes neuronales, en nuestro caso un MLP (Multi Layer Preceptron)\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "#Libreria de hora y fecha\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "#Librerias para realizar preprocesado de datos (Transformaciones y estandarizacion)\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "plt.style.use('seaborn-poster')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargando el archivo CSV en memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cargamos el CSV en memoria\n",
    "cuiles = pd.read_csv('cuiles2.csv', names = [\"CUIL\", \"Nacimiento\", \"Sexo\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando la instancia de regresor utilizando un MLP (Multi Layer Perceptron)\n",
    "\n",
    "#### Multi Layer Perceptron (Perceptrón Multicapa)\n",
    "Utilizamos un tipo de red neuronal llamado Perceptrón Multicapa, el mismo consta de 4 capas, compuestas por 200 perceptrones para la entrada, 400 y 400 en sus capas ocultas, y 200 en sus capas de salida.\n",
    "Utilizamos el algoritmo adam (https://arxiv.org/abs/1412.6980) a que provee una excelente respuesta para datasets con mas de 100 registros; cuya funcion de activación es la de rectificador (ReLU), es decir sus valores van desde 0 a f(x) = max(x) es decir, el valor maximo del dataset de entrada.\n",
    "Esto es particularmente útil dado que probando otro tipo de funciones, como la tangente hiperbolica, se obtinen resultados escalados y suponemos se requeriria una especie de postproceso para reconvertir la salida al dominio de la entrada. Con ReLU nos aseguramos conservar la escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12366,     1],\n",
       "       [16476,     0],\n",
       "       [15689,     0],\n",
       "       ..., \n",
       "       [23534,     0],\n",
       "       [15788,     0],\n",
       "       [19723,     0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creamos el objeto MLP con las opciones definidas en su constructor\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(200,400,400,200), max_iter = 2000, solver='adam', \\\n",
    "                   alpha=0.01, activation = 'relu', random_state = 9)\n",
    "\n",
    "\n",
    "x = cuiles['Nacimiento']\n",
    "z = cuiles['Sexo']\n",
    "y = cuiles['CUIL']\n",
    "\n",
    "#Convertimos z en 1 y 0\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(z)\n",
    "z = le.transform(z)\n",
    "\n",
    "#Ponemos cantidad de dias\n",
    "x =  [((datetime.now() - datetime.strptime(item, '%d-%m-%Y')).days) for item in cuiles['Nacimiento']]\n",
    "\n",
    "#Creamos la matriz de features, es decir [[Cantidad de dias pasados , Sexo]]\n",
    "X = np.column_stack((x,z))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tratamiento a los datos de entrada\n",
    "Los datos de entrada constan de una matriz de 2xN formada por [Cantidad de dias, Sexo], utilizamos\n",
    "cantidad de días dado que debemos darle una entrada representativa a la red neuronal, que pueda aprender.\n",
    "No podemos usar un dato tipo cadena de texto dado que no guardaria una relacion con el dominio del problema.\n",
    "\n",
    "La columna Sexo, tambien es estandarizada a 0 y 1, siendo 0 Femenino y 1 Hombre.\n",
    "\n",
    "#### Probando la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creamos un vector de features que deseamos evaluar para obtener un posible CUIT\n",
    "predecir = [[((datetime.now() - datetime.strptime('09-07-1989', '%d-%m-%Y')).days), le.transform(['M'])[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ezequiel/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#MLP resultó tras muchísimas pruebas ser muy sensible a las diferentes escalas y rangos de datos\n",
    "#Por eso realizamos un escalamiento de -1 a 1 en la matriz de entrada\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X)  \n",
    "X = scaler.transform(X)\n",
    "\n",
    "\n",
    "#print(y)\n",
    "#y = y.tolist()\n",
    "#scaler = StandardScaler()  \n",
    "#scaler.fit(y)  \n",
    "#y = scaler.transform(y)\n",
    "\n",
    "\n",
    "predecir = scaler.transform(predecir)\n",
    "\n",
    "\n",
    "mlp = mlp.fit(X, y)\n",
    "yfit = mlp.predict(predecir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Resultados\n",
    "Deseamos predecir el vector: [ 09-07-1989 , M ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.60046228  1.56090554]]\n"
     ]
    }
   ],
   "source": [
    "print(predecir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y obtenemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20979738158\n"
     ]
    }
   ],
   "source": [
    "print(int(yfit[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valor real: 20345553062"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
