{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP N° 2\n",
    "## Obteniendo un posible CUIT a partir de una fecha de nacimiento y género"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Libreria para tratar con Arrays y otro tipos de datos utilizados\n",
    "import numpy as np\n",
    "\n",
    "# Libreria para graficar\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Libreria que probee herramientas para el manejo de datos\n",
    "import pandas as pd\n",
    "\n",
    "# Libreria que incluye redes neuronales, en nuestro caso un MLP (Multi Layer Preceptron)\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Libreria de hora y fecha\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# Librerias para realizar preprocesado de datos (Transformaciones y estandarizacion)\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "plt.style.use('seaborn-poster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargando el archivo CSV en memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            CUIL  Nacimiento Sexo\n",
      "79   20202755977  02-04-1969    M\n",
      "94   20286985913  01-01-1970    M\n",
      "398  27144337021  19-10-1960    F\n",
      "322  20165840462  11-02-1963    M\n",
      "783  27336138545  10-03-1988    F\n",
      "604  20268870793  13-10-1978    M\n",
      "995  27126398331  16-09-1956    F\n",
      "285  23251849714  01-01-1970    F\n",
      "814  27288336356  01-09-1981    F\n",
      "947  27259149083  13-05-1977    F\n",
      "958  23132632154  21-03-1959    F\n",
      "788  27174320727  11-01-1965    F\n",
      "203  27066579439  23-12-1947    F\n",
      "335  27926707642  13-07-1958    F\n",
      "929  20149010611  12-01-1962    M\n",
      "111  27926242666  19-05-1957    F\n",
      "63   20165062532  02-05-1963    M\n",
      "270  20178738594  09-02-1966    M\n",
      "786  27294002702  13-03-1982    F\n",
      "910  27176180264  13-10-1963    F\n",
      "137  27133146917  25-05-1959    F\n",
      "663  23211552484  26-10-1969    F\n",
      "690  27326863217  22-02-1987    F\n",
      "344  27125145006  18-07-1958    F\n",
      "883  23272834644  15-09-1979    F\n",
      "381  20238439532  31-05-1974    M\n",
      "105  23174542384  21-05-1965    F\n",
      "369  27294973708  04-06-1982    F\n",
      "313  27235092323  04-09-1973    F\n",
      "773  20177807975  19-11-1967    M\n",
      "..           ...         ...  ...\n",
      "391  20310616703  05-07-1984    M\n",
      "487  27229279578  19-12-1972    F\n",
      "233  27237672416  16-04-1974    F\n",
      "882  27132854055  09-04-1959    F\n",
      "869  20216145705  16-06-1970    M\n",
      "349  27363575825  10-06-1992    F\n",
      "319  27302014839  25-06-1983    F\n",
      "640  27296595433  13-08-1982    F\n",
      "277  20134310872  04-09-1959    M\n",
      "108  20116338085  11-06-1955    M\n",
      "623  27169140672  26-06-1964    F\n",
      "506  27179702164  30-09-1966    F\n",
      "930  27254366582  20-08-1976    F\n",
      "767  27103562703  28-04-1952    F\n",
      "891  20177168603  22-04-1966    M\n",
      "785  27232460321  28-01-1973    F\n",
      "832  27209112243  09-07-1969    F\n",
      "173  27134051138  15-01-1957    F\n",
      "493  27265345714  12-04-1978    F\n",
      "155  23284388364  08-12-1980    F\n",
      "753  27254313802  01-01-1970    F\n",
      "596  23130173624  22-03-1957    F\n",
      "72   23229855344  09-12-1975    F\n",
      "826  27184638075  06-11-1967    F\n",
      "273  27323841050  24-04-1986    F\n",
      "342  27343743497  27-01-1989    F\n",
      "324  27171083023  16-08-1964    F\n",
      "200  20290413770  14-09-1981    M\n",
      "416  27229748713  16-11-1972    F\n",
      "185  27327372993  01-01-1970    F\n",
      "\n",
      "[750 rows x 3 columns]\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "            CUIL  Nacimiento Sexo\n",
      "13   20261806348  06-12-1977    M\n",
      "15   20181405547  23-05-1967    M\n",
      "19   27170761125  01-01-1970    F\n",
      "23   27305314345  12-11-1983    F\n",
      "29   23290924464  10-02-1982    F\n",
      "30   27171734075  12-04-1963    F\n",
      "32   20224119292  23-03-1972    M\n",
      "34   20135158799  03-11-1957    M\n",
      "38   27225094034  26-03-1972    F\n",
      "43   23179900009  05-09-1967    M\n",
      "47   27183073600  27-06-1967    F\n",
      "54   27182364954  09-12-1967    F\n",
      "55   27211404057  23-11-1969    F\n",
      "66   27233320310  05-03-1973    F\n",
      "69   27253020151  16-04-1976    F\n",
      "71   27141524726  03-07-1961    F\n",
      "73   27230112512  27-05-1973    F\n",
      "75   27236704284  26-12-1973    F\n",
      "78   27293189434  10-02-1982    F\n",
      "81   27316616149  12-09-1985    F\n",
      "89   27261093214  08-12-1977    F\n",
      "91   23146118429  18-11-1961    M\n",
      "97   27216243736  28-05-1970    F\n",
      "99   20124479445  20-09-1958    M\n",
      "101  23234715399  11-10-1973    M\n",
      "102  27265009315  09-05-1978    F\n",
      "110  27149882451  20-06-1962    F\n",
      "113  27224976106  22-04-1972    F\n",
      "114  27288609468  09-05-1981    F\n",
      "123  20143214878  30-03-1961    M\n",
      "..           ...         ...  ...\n",
      "857  20080191171  28-02-1950    M\n",
      "865  27279397326  07-02-1980    F\n",
      "866  27314074764  01-01-1985    F\n",
      "870  27287558150  10-05-1981    F\n",
      "878  27136553947  31-12-1959    F\n",
      "881  27298321039  17-07-1983    F\n",
      "893  27166377256  05-02-1963    F\n",
      "904  20283812104  04-08-1980    M\n",
      "905  20208609298  17-07-1969    M\n",
      "906  27169760360  21-05-1964    F\n",
      "907  23250242824  22-11-1975    F\n",
      "911  20232483971  20-02-1973    M\n",
      "912  20320792488  12-05-1986    M\n",
      "914  27190417757  21-06-1969    F\n",
      "919  27280666748  04-03-1980    F\n",
      "920  27140100825  02-05-1960    F\n",
      "922  20134046881  02-12-1957    M\n",
      "933  27176312810  04-03-1965    F\n",
      "939  27203314987  26-02-1969    F\n",
      "944  27121068678  28-02-1958    F\n",
      "946  23231198644  15-02-1973    F\n",
      "950  27306511322  28-11-1983    F\n",
      "956  27224711447  06-11-1971    F\n",
      "964  20116188695  14-06-1955    M\n",
      "970  20234714571  14-09-1973    M\n",
      "971  20182052486  18-10-1966    M\n",
      "978  20250220031  08-12-1975    M\n",
      "980  27175580439  10-07-1965    F\n",
      "985  20293188689  13-01-1982    M\n",
      "997  27110301958  19-12-1953    F\n",
      "\n",
      "[250 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el CSV en memoria\n",
    "cuiles = pd.read_csv('cuiles2.csv', names = [\"CUIL\", \"Nacimiento\", \"Sexo\"])\n",
    "\n",
    "# Definimos los datasets de entrenamiento y prueba\n",
    "train = cuiles.sample(frac=0.75)\n",
    "test = cuiles.drop(train.index)\n",
    "\n",
    "print(train)\n",
    "print('\\n-------------------------------------------\\n')\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando la instancia de regresor utilizando un MLP (Multi Layer Perceptron)\n",
    "\n",
    "#### Multi Layer Perceptron (Perceptrón Multicapa)\n",
    "Utilizamos un tipo de red neuronal llamado Perceptrón Multicapa, el mismo consta de 4 capas, compuestas por 200 perceptrones para la entrada, 400 y 400 en sus capas ocultas, y 200 en sus capas de salida.\n",
    "Utilizamos el algoritmo adam (https://arxiv.org/abs/1412.6980) a que provee una excelente respuesta para datasets con mas de 100 registros; cuya funcion de activación es la de rectificador (ReLU), es decir sus valores van desde 0 a f(x) = max(x) es decir, el valor maximo del dataset de entrada.\n",
    "Esto es particularmente útil dado que probando otro tipo de funciones, como la tangente hiperbolica, se obtinen resultados escalados y suponemos se requeriria una especie de postproceso para reconvertir la salida al dominio de la entrada. Con ReLU nos aseguramos conservar la escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17951     1]\n",
      " [17677     1]\n",
      " [21038     0]\n",
      " ...\n",
      " [13403     1]\n",
      " [16627     0]\n",
      " [17677     0]]\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "[[14781     1]\n",
      " [18631     1]\n",
      " [17677     0]\n",
      " [12614     0]\n",
      " [13254     0]\n",
      " [20133     0]\n",
      " [16865     1]\n",
      " [22119     1]\n",
      " [16862     0]\n",
      " [18526     1]\n",
      " [18596     0]\n",
      " [18431     0]\n",
      " [17716     0]\n",
      " [16518     0]\n",
      " [15380     0]\n",
      " [20781     0]\n",
      " [16435     0]\n",
      " [16222     0]\n",
      " [13254     0]\n",
      " [11944     0]\n",
      " [14779     0]\n",
      " [20643     1]\n",
      " [17530     0]\n",
      " [21798     1]\n",
      " [16298     1]\n",
      " [14627     0]\n",
      " [20429     0]\n",
      " [16835     0]\n",
      " [13531     0]\n",
      " [20876     1]\n",
      " [14688     0]\n",
      " [20135     0]\n",
      " [14059     0]\n",
      " [ 9727     0]\n",
      " [23571     0]\n",
      " [13040     0]\n",
      " [20686     0]\n",
      " [15363     1]\n",
      " [20657     0]\n",
      " [12825     0]\n",
      " [22115     1]\n",
      " [13843     1]\n",
      " [17677     0]\n",
      " [12462     1]\n",
      " [14012     1]\n",
      " [12557     0]\n",
      " [19932     0]\n",
      " [20355     0]\n",
      " [14693     1]\n",
      " [19091     0]\n",
      " [21351     0]\n",
      " [17425     1]\n",
      " [14091     0]\n",
      " [19999     0]\n",
      " [ 8882     0]\n",
      " [19962     1]\n",
      " [14508     0]\n",
      " [17677     0]\n",
      " [14150     0]\n",
      " [13057     0]\n",
      " [18823     0]\n",
      " [23037     1]\n",
      " [14646     1]\n",
      " [11916     1]\n",
      " [20141     1]\n",
      " [14416     1]\n",
      " [18835     0]\n",
      " [16628     0]\n",
      " [17677     0]\n",
      " [20397     0]\n",
      " [17677     1]\n",
      " [19337     0]\n",
      " [15329     1]\n",
      " [15403     0]\n",
      " [21795     0]\n",
      " [18835     0]\n",
      " [19102     0]\n",
      " [16067     1]\n",
      " [18811     0]\n",
      " [22807     0]\n",
      " [17677     0]\n",
      " [12768     1]\n",
      " [11534     1]\n",
      " [16888     0]\n",
      " [13032     0]\n",
      " [17245     0]\n",
      " [21720     0]\n",
      " [13633     0]\n",
      " [13373     1]\n",
      " [11833     0]\n",
      " [15762     1]\n",
      " [14756     0]\n",
      " [10336     0]\n",
      " [18657     0]\n",
      " [10907     0]\n",
      " [12871     0]\n",
      " [15033     0]\n",
      " [15157     0]\n",
      " [16517     1]\n",
      " [14323     1]\n",
      " [20403     0]\n",
      " [17027     0]\n",
      " [22218     0]\n",
      " [15165     0]\n",
      " [20727     1]\n",
      " [18904     0]\n",
      " [19457     1]\n",
      " [14289     0]\n",
      " [16594     0]\n",
      " [16219     0]\n",
      " [17677     0]\n",
      " [18883     0]\n",
      " [16594     0]\n",
      " [11725     0]\n",
      " [16479     0]\n",
      " [18105     1]\n",
      " [12290     1]\n",
      " [16594     0]\n",
      " [16479     0]\n",
      " [16479     0]\n",
      " [13457     1]\n",
      " [20428     0]\n",
      " [ 9901     1]\n",
      " [14890     0]\n",
      " [21720     0]\n",
      " [12078     1]\n",
      " [21720     0]\n",
      " [ 8882     0]\n",
      " [17507     0]\n",
      " [13257     1]\n",
      " [13314     0]\n",
      " [12532     0]\n",
      " [10366     1]\n",
      " [16994     0]\n",
      " [11760     0]\n",
      " [17816     0]\n",
      " [17963     0]\n",
      " [17740     0]\n",
      " [21818     0]\n",
      " [21422     0]\n",
      " [21481     1]\n",
      " [19924     1]\n",
      " [17917     0]\n",
      " [14283     0]\n",
      " [11399     1]\n",
      " [12345     1]\n",
      " [17145     0]\n",
      " [ 9270     1]\n",
      " [14862     0]\n",
      " [19125     0]\n",
      " [17110     0]\n",
      " [12919     1]\n",
      " [19897     1]\n",
      " [16647     1]\n",
      " [13570     0]\n",
      " [18074     1]\n",
      " [18657     1]\n",
      " [22693     0]\n",
      " [10651     0]\n",
      " [22631     0]\n",
      " [13684     0]\n",
      " [21328     1]\n",
      " [16479     0]\n",
      " [15739     0]\n",
      " [12297     0]\n",
      " [20975     1]\n",
      " [20242     0]\n",
      " [21481     0]\n",
      " [19192     0]\n",
      " [16010     0]\n",
      " [20159     0]\n",
      " [17677     1]\n",
      " [19112     0]\n",
      " [21312     0]\n",
      " [18508     0]\n",
      " [17677     1]\n",
      " [14396     0]\n",
      " [20142     0]\n",
      " [11961     0]\n",
      " [22326     1]\n",
      " [14182     1]\n",
      " [19792     0]\n",
      " [14059     0]\n",
      " [21831     0]\n",
      " [13521     0]\n",
      " [12041     1]\n",
      " [21071     0]\n",
      " [ 9597     0]\n",
      " [17677     1]\n",
      " [16671     1]\n",
      " [17596     0]\n",
      " [10183     1]\n",
      " [17677     1]\n",
      " [14510     0]\n",
      " [19738     1]\n",
      " [14512     0]\n",
      " [14973     0]\n",
      " [15959     0]\n",
      " [18533     0]\n",
      " [17420     0]\n",
      " [11737     0]\n",
      " [19820     0]\n",
      " [19574     1]\n",
      " [20285     0]\n",
      " [16573     0]\n",
      " [16472     1]\n",
      " [15100     0]\n",
      " [11952     0]\n",
      " [12913     0]\n",
      " [18745     1]\n",
      " [14275     0]\n",
      " [12211     0]\n",
      " [12668     1]\n",
      " [17468     1]\n",
      " [17111     0]\n",
      " [16640     1]\n",
      " [18446     1]\n",
      " [12691     1]\n",
      " [22922     0]\n",
      " [17677     0]\n",
      " [24924     1]\n",
      " [13988     0]\n",
      " [12198     0]\n",
      " [13530     0]\n",
      " [21331     0]\n",
      " [12732     0]\n",
      " [20199     0]\n",
      " [13809     1]\n",
      " [17845     1]\n",
      " [19728     0]\n",
      " [15526     0]\n",
      " [16531     1]\n",
      " [11702     1]\n",
      " [17871     0]\n",
      " [13962     0]\n",
      " [21208     0]\n",
      " [22090     1]\n",
      " [19441     0]\n",
      " [17986     0]\n",
      " [22002     0]\n",
      " [16536     0]\n",
      " [12598     0]\n",
      " [17003     0]\n",
      " [22992     1]\n",
      " [16325     1]\n",
      " [18848     1]\n",
      " [15510     1]\n",
      " [19313     0]\n",
      " [13282     1]\n",
      " [23534     0]]\n"
     ]
    }
   ],
   "source": [
    "# Creamos el objeto MLP con las opciones definidas en su constructor\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(200,400,400,200), max_iter = 2000, solver='adam', \\\n",
    "                   alpha=0.01, activation = 'relu', random_state = 9)\n",
    "\n",
    "def nacimiento_a_dias(arr): \n",
    "    return [((datetime.now() - datetime.strptime(item, '%d-%m-%Y')).days) for item in arr]\n",
    "\n",
    "# Features de entrenamiento\n",
    "x_train = nacimiento_a_dias(train['Nacimiento'])\n",
    "z_train = train['Sexo']\n",
    "\n",
    "# Labels de entrenamiento\n",
    "y_train = train['CUIL'].astype(float)\n",
    "\n",
    "# Features de prueba\n",
    "x_test = nacimiento_a_dias(test['Nacimiento'])\n",
    "z_test = test['Sexo']\n",
    "\n",
    "# Labels de prueba\n",
    "y_test = test['CUIL'].astype(float)\n",
    "\n",
    "# Convertimos la feature z a 1 y 0\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(z_train)\n",
    "z_train = le.transform(z_train)\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(z_test)\n",
    "z_test = le.transform(z_test)\n",
    "\n",
    "#Creamos la matriz de features, es decir [[Cantidad de dias pasados , Sexo]]\n",
    "X_train = np.column_stack((x_train, z_train))\n",
    "X_test = np.column_stack((x_test, z_test))\n",
    "\n",
    "print(X_train)\n",
    "print('\\n-------------------------------------------\\n')\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tratamiento a los datos de entrada\n",
    "Los datos de entrada constan de una matriz de 2xN formada por [Cantidad de dias, Sexo], utilizamos\n",
    "cantidad de días dado que debemos darle una entrada representativa a la red neuronal, que pueda aprender.\n",
    "No podemos usar un dato tipo cadena de texto dado que no guardaria una relacion con el dominio del problema.\n",
    "\n",
    "La columna Sexo, tambien es estandarizada a 0 y 1, siendo 0 Femenino y 1 Hombre.\n",
    "\n",
    "#### Probando la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mario\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entrenamiento: 114.529s\n"
     ]
    }
   ],
   "source": [
    "# MLP resultó tras muchísimas pruebas ser muy sensible a las diferentes escalas y rangos de datos\n",
    "# Por eso realizamos un escalamiento de -1 a 1 en la matriz de entrada\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)  \n",
    "X_train = scaler.transform(X_train)\n",
    "scaler.fit(X_test)  \n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#y = y.tolist()\n",
    "#scaler = StandardScaler()  \n",
    "#scaler.fit(y)  \n",
    "#y = scaler.transform(y)\n",
    "\n",
    "t0 = time()\n",
    "mlp = mlp.fit(X_train, y_train)\n",
    "pred = mlp.predict(X_train)\n",
    "\n",
    "print(f\"Tiempo de entrenamiento: {round(time()-t0, 3)}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Resultados\n",
    "Verificamos la exactitud de la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (250, 2) and (750,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-199-89ec1a0794b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#print(np.array(y_test), np.array(pred))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   3259\u001b[0m                       mplDeprecation)\n\u001b[0;32m   3260\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3261\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3262\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3263\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1715\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[0;32m   1716\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1717\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1718\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1719\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1370\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1372\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1373\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m             \u001b[0mlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    382\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'plot'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[1;32m--> 243\u001b[1;33m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[0;32m    244\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (250, 2) and (750,)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAw0AAAIQCAYAAADD3oIRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAHVFJREFUeJzt3X+s7Hdd5/HXu70CtppwGyRG7U/LQm8DErirDaCB7mqLum02uEhULC5U1LjC7qqBrVZt64qiYIC4/FhWm4KB0LBpdVUqbUFt7JpedtvtrVKKtxYNhuq9tLQFpPLZP2bO7vH09H2+58w590xvH49kMud+Zz4zn0m/nXOe8/0xNcYIAADAozlutycAAAAsN9EAAAC0RAMAANASDQAAQEs0AAAALdEAAAC0JkVDVX1DVb21qv60qh6qqlFVp00ce1xVvb6q7q6qL1TVrVX1kkUmDQAAHD1TtzScmeSlSY4k+eNNPsflSX4+yduSvDjJzUk+UFXfucnHAQAAdkFN+XK3qjpujPHl+c+vSvKuJKePMe7eYNxTk3wqyRvGGD+3avn1Sb5mjPGsBeYOAAAcBZO2NKwEwxacl+QJSd6zZvl7kjyzqk7f4uMCAABHyU4fCH12ki8muWvN8oPz6307/PwAAMCC9uzw45+U5LPjkftAHV51+6ZU1YGVn8cYz11gbgAAwAQ7HQ2VZL2DJmo7HvwpT3nKOO2007bjoQAA4Jhy4MCBvxtjfM12PNZOR8PhJHurqtZsbdi76vZNWb11Yf/+/eOWW25ZcIoAAHDsqaq/2q7H2uljGg4meWKSb1yzfOVYhjt2+PkBAIAF7XQ0/EGSf0jy/WuW/0CS28cYh3b4+QEAgAVN3j2pqr5n/uPK7kEvrqp7k9w7xvjo/D4PJ7lyjPHKJBljfKaq3pzk9VX1uSQfS/K9Sc5NcuE2vQYAAGAHbeaYhg+s+fdvzK8/muSF85+Pn19WuyTJA0lek+Rrk3w8yUvHGL+zqZkCAAC7YnI0jDE2POPRevcZY/xjkivmFwAA4DFmp49pAAAAHuNEAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABAa1I0VNXJVXV1Vd1XVfdX1Qer6pSJY0+pqiur6p6qeqiq7qyqK6rqxMWmDgAAHA17NrpDVZ2Q5IYkX0xyUZKR5IokN1bVs8YYDzZjT0zy4SRfkeRnk9yT5J8n+YUkT0vyvYu+AAAAYGdtGA1JLk5yRpKnjzHuSpKqui3JJ5K8OsmbmrHPzywOzhtjXDdfdmNVnZTkJ6vqhDHGQ1uePQAAsOOm7J50QZKbV4IhScYYh5LclOTCDcY+YX59/5rln50/d02cJwAAsEumRMPZSW5fZ/nBJPs2GPvhzLZI/HJV7auqr6qqc5O8Jsnbu12bHk1VHVi5bHYsAACweVOi4aQkR9ZZfjjJ3m7gGOMLSV4wf56DST6X5Pokv5vkxzc1UwAAYFdMOaYhmR38vNaGuxZV1ZOSvD/JU5O8PLMDob85yaVJHk7yoxOf//9PZIznrvy8f//+9eYFAABsoynRcCSzrQ1r7c36WyBWe2WSFyY5c4zxyfmyP6qq+5K8s6rePsa4depkAQCAo2/K7kkHMzuuYa19Se7YYOwzkxxZFQwr/mx+fdaE5wcAAHbRlGi4Nsk5VXXGyoKqOi2z06leu8HYv02yt6rOXLP8W+bXfzNtmgAAwG6ZEg3vSnJ3kmuq6sKquiDJNUk+leQdK3eqqlOr6uGqunTV2N/K7ODn36uqi6rqRVX1U0l+NcmBzE7bCgAALLENo2F+WtRzk9yZ5Kok701yKMm5Y4wHVt21khy/+jHHGHcnOSfJ/87sW6R/L7Mvi3tnkm8fY3x5W14FAACwYyadPWmMcU+Sl2xwn7uzzhmVxhh3JHnpViYHAADsvim7JwEAAI9jogEAAGiJBgAAoCUaAACAlmgAAABaogEAAGiJBgAAoCUaAACAlmgAAABaogEAAGiJBgAAoCUaAACAlmgAAABaogEAAGiJBgAAoCUaAACAlmgAAABaogEAAGiJBgAAoCUaAACAlmgAAABaogEAAGiJBgAAoCUaAACAlmgAAABaogEAAGiJBgAAoCUaAACAlmgAAABaogEAAGiJBgAAoCUaAACAlmgAAABaogEAAGiJBgAAoCUaAACAlmgAAABaogEAAGiJBgAAoCUaAACAlmgAAABaogEAAGiJBgAAoCUaAACAlmgAAABaogEAAGiJBgAAoCUaAACAlmgAAABaogEAAGiJBgAAoCUaAACAlmgAAABaogEAAGiJBgAAoCUaAACAlmgAAABaogEAAGiJBgAAoCUaAACAlmgAAABaogEAAGiJBgAAoCUaAACAlmgAAABaogEAAGiJBgAAoCUaAACAlmgAAABaogEAAGiJBgAAoCUaAACAlmgAAABaogEAAGiJBgAAoCUaAACAlmgAAABaogEAAGiJBgAAoCUaAACAlmgAAABaogEAAGiJBgAAoDUpGqrq5Kq6uqruq6r7q+qDVXXK1CepqrOq6gNV9XdV9fmq+nhVvWbr0wYAAI6WPRvdoapOSHJDki8muSjJSHJFkhur6lljjAc3GL9/Pv4jSV6V5L4kT0vyVQvNHAAAOCo2jIYkFyc5I8nTxxh3JUlV3ZbkE0leneRNjzawqo5LcmWS68cY/3rVTTduecYAAMBRNWX3pAuS3LwSDEkyxjiU5KYkF24w9oVJ9qUJCwAAYLlNiYazk9y+zvKDmQVB5wXz6ydV1c1V9aWq+kxVvaWqvnIzE11RVQdWLlsZDwAAbM6UaDgpyZF1lh9OsneDsV83v35/kuuSfHuSX8ns2IbfnjhHAABgF005piGZHfy8Vk0YtxIl7xljXDr/+SNVdXySN1TVvjHGHRPnMJvIGM9d+Xn//v3rzQsAANhGU7Y0HMlsa8Nae7P+FojV/n5+/Ydrll83v372hOcHAAB20ZRoOJjZcQ1r7Uuy0VaCg/PrtVsEVrZSfHnC8wMAALtoSjRcm+ScqjpjZUFVnZbk+fPbOr+f2fc7nL9m+Xnz61smzRIAANg1U6LhXUnuTnJNVV1YVRckuSbJp5K8Y+VOVXVqVT1cVSvHLmSM8fdJfinJj1TVf66qf1lVr0tyaZIrV5/GFQAAWE4bHgg9xniwqs5N8uYkV2W2a9H1SV47xnhg1V0ryfF5ZIhcluRzSX4syU8m+XSSNya5fOHZAwAAO27S2ZPGGPckeckG97k765xRaYwxMvtyN1/wBgAAj0FTdk8CAAAex0QDAADQEg0AAEBLNAAAAC3RAAAAtEQDAADQEg0AAEBLNAAAAC3RAAAAtEQDAADQEg0AAEBLNAAAAC3RAAAAtEQDAADQEg0AAEBLNAAAAC3RAAAAtEQDAADQEg0AAEBLNAAAAC3RAAAAtEQDAADQEg0AAEBLNAAAAC3RAAAAtEQDAADQEg0AAEBLNAAAAC3RAAAAtEQDAADQEg0AAEBLNAAAAC3RAAAAtEQDAADQEg0AAEBLNAAAAC3RAAAAtEQDAADQEg0AAEBLNAAAAC3RAAAAtEQDAADQEg0AAEBLNAAAAC3RAAAAtEQDAADQEg0AAEBLNAAAAC3RAAAAtEQDAADQEg0AAEBLNAAAAC3RAAAAtEQDAADQEg0AAEBLNAAAAC3RAAAAtEQDAADQEg0AAEBLNAAAAC3RAAAAtEQDAADQEg0AAEBLNAAAAC3RAAAAtEQDAADQEg0AAEBLNAAAAC3RAAAAtEQDAADQEg0AAEBLNAAAAC3RAAAAtEQDAADQEg0AAEBLNAAAAC3RAAAAtEQDAADQEg0AAEBLNAAAAC3RAAAAtEQDAADQmhQNVXVyVV1dVfdV1f1V9cGqOmWzT1ZVr6+qUVV/svmpAgAAu2HDaKiqE5LckOQZSS5K8vIkT0tyY1WdOPWJquqMJJck+czWpgoAAOyGPRPuc3GSM5I8fYxxV5JU1W1JPpHk1UneNPG5/kuS9yZ5+sTnBQAAlsCU3ZMuSHLzSjAkyRjjUJKbklw45Umq6vuSPCfJ67cySQAAYPdMiYazk9y+zvKDSfZtNLiq9iZ5c5KfHmMc3tz0AACA3TYlGk5KcmSd5YeT7J0w/o1J7kzyW9On9eiq6sDKZTseDwAA6E09tmCss6w2GlRV35rkB5M8Z4yx3mMAAABLbsqWhiOZbW1Ya2/W3wKx2juSvDvJX1fVk6vqyZmFyvHzfz9xU7NNMsZ47spls2MBAIDNm7Kl4WBmxzWstS/JHRuMPWt++ZF1bjuS5N8n+fUJcwAAAHbJlGi4NsmvVtUZY4y/TJKqOi3J85O8boOxL1pn2a8nOT7Jv0ty1zq3AwAAS2RKNLwryY8nuaaqfiaz4xsuT/KpzHY/SpJU1alJPpnksjHGZUkyxvjI2gerqs8m2bPebQAAwPLZ8JiGMcaDSc7N7AxIV2X2BW2Hkpw7xnhg1V0rsy0IU46TAAAAHiMmnT1pjHFPkpdscJ+7M+GMSmOMF055TgAAYDnYKgAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABASzQAAAAt0QAAALREAwAA0BINAABAa1I0VNXJVXV1Vd1XVfdX1Qer6pQJ4/ZX1Tur6i+q6qGquqeq3ltVpy8+dQAA4GjYMBqq6oQkNyR5RpKLkrw8ydOS3FhVJ24w/GVJzk7yliQvTvK6JM9JcktVnbzAvAEAgKNkz4T7XJzkjCRPH2PclSRVdVuSTyR5dZI3NWN/eYxx7+oFVXVTkkPzx710K5MGAACOnim7J12Q5OaVYEiSMcahJDclubAbuDYY5sv+Ksm9Sb5+c1MFAAB2w5RoODvJ7essP5hk32afsKrOSvLUJH++2bHz8QdWLlsZDwAAbM6UaDgpyZF1lh9OsnczT1ZVe5K8PbMtDe/ezFgAAGB3TD3l6lhnWW3h+d6W5HlJfmCMsV6IbDyRMZ67ctnKeAAAYHOmHAh9JLOtDWvtzfpbINZVVb+U5IeTXDTGuG7qOAAAYHdNiYaDmR3XsNa+JHdMeZKquiSz063+xBjjqunTAwAAdtuU3ZOuTXJOVZ2xsqCqTkvy/Pltrar6iSRXJLlkjPHWrU0TAADYLVOi4V1J7k5yTVVdWFUXJLkmyaeSvGPlTlV1alU9XFWXrlr2siS/nuQPktxQVeesumz6zEsAAMDRt+HuSWOMB6vq3CRvTnJVZgdAX5/ktWOMB1bdtZIcn38aIufPl58/v6z20SQv3PLMAQCAo2LKMQ0ZY9yT5CUb3OfurDmj0hjjFUlesbWpAQAAy2DqKVcBAIDHKdEAAAC0RAMAANASDQAAQEs0AAAALdEAAAC0RAMAANASDQAAQEs0AAAALdEAAAC0RAMAANASDQAAQEs0AAAALdEAAAC0RAMAANASDQAAQEs0AAAALdEAAAC0RAMAANASDQAAQEs0AAAALdEAAAC0RAMAANASDQAAQEs0AAAALdEAAAC0RAMAANASDQAAQEs0AAAALdEAAAC0RAMAANASDQAAQEs0AAAALdEAAAC0RAMAANASDQAAQEs0AAAALdEAAAC0RAMAANASDQAAQEs0AAAALdEAAAC0RAMAANASDQAAQEs0AAAALdEAAAC0RAMAANASDQAAQEs0AAAALdEAAAC0RAMAANASDQAAQEs0AAAALdEAAAC0RAMAANASDQAAQEs0AAAALdEAAAC0RAMAANASDQAAQEs0AAAALdEAAAC0RAMAANASDQAAQEs0AAAALdEAAAC0RAMAANASDQAAQEs0AAAALdEAAAC0RAMAANASDQAAQEs0AAAALdEAAAC0RAMAANASDQAAQEs0AAAALdEAAAC0RAMAANASDQAAQEs0AAAALdEAAAC0RAMAANCaFA1VdXJVXV1V91XV/VX1wao6ZeLYJ1XVG6vq01X1+ar606r6tsWmDQAAHC0bRkNVnZDkhiTPSHJRkpcneVqSG6vqxAnP8e4kFye5NMl3J/l0kg9V1bO3OmkAAODo2TPhPhcnOSPJ08cYdyVJVd2W5BNJXp3kTY82sKq+Kcn3Jfm3Y4zfnC/7aJKDSS5LcsFCswcAAHbclN2TLkhy80owJMkY41CSm5JcOGHsl5K8f9XYh5O8L8l5VfXETc8YAAA4qqZEw9lJbl9n+cEk+yaMPTTGeGidsU9IcuaE5/8nqurAymWzYwEAgM2bsnvSSUmOrLP8cJK9C4xduX2rnnHgwIGHq+rWBR6Dx6ez5td/vquz4LHIusNWWXfYKusOW3VWkm/argebEg1JMtZZVhPG1QJj15/IGM9NZlsc5v/ev9XH4vHJusNWWXfYKusOW2XdYau2e6+cKbsnHcn6WwT2Zv2tCKsdbsau3A4AACyxKdFwMLNjE9bal+SOCWNPn5+2de3Yf0hy1yOHAAAAy6TGWG/voVV3qHptkl9N8s/GGH85X3ZaZqdcfd0Y49easc9O8r+SvGKMceV82Z4k/yfJXWOMf7UNrwEAANhBU6LhxCS3Jvl8kp/J7BiFy5N8dZJnjTEemN/v1CSfTHLZGOOyVePfl+S8JD+V5FCSH83sS96eN8b42Ha/IAAAYHttuHvSGOPBJOcmuTPJVUnem9kf/+euBMNcJTl+ncf8oSS/meSKJP8jyclJzhcMAADw2LDhlgYAAODxbcqB0AAAwOOYaAAAAFqiAQAAaIkGAACgJRoAAICWaAAAAFqiAQAAaC1lNFTVyVV1dVXdV1X3V9UHq+qUiWOfVFVvrKpPV9Xnq+pPq+rbdnrOLIetrjtVtb+q3llVf1FVD1XVPVX13qo6/WjMm921yHvOmsd5fVWNqvqTnZgny2fRdaeqzqqqD1TV381/Z328ql6zk3NmOSz4t84pVXXl/HfVQ1V1Z1VdUVUn7vS82X1V9Q1V9db537gPzX/vnDZx7HHz31V3V9UXqurWqnrJlLFLFw1VdUKSG5I8I8lFSV6e5GlJbpz4P8O7k1yc5NIk353k00k+VFXP3pkZsywWXHdeluTsJG9J8uIkr0vynCS3VNXJOzZpdt02vOesPM4ZSS5J8pmdmCfLZ9F1p6r2J/mfSZ6Y5FVJvjPJryU5fqfmzHJYZN2Z3/7hJN+W5GeTfFeS/5rkPyb5bzs4bZbHmUlemuRIkj/e5NjLk/x8krdl9vfOzUk+UFXfueHIMcZSXZK8Jsk/Jjlz1bLTkzyc5D9sMPabkowkP7Rq2Z4kH09y7W6/NpelXne+Zp1lpyb5cpLLdvu1uSznerPmcT6U5B1JPpLkT3b7dbns/GXB95zjkhxM8t93+3W4HP3LguvOd8z/1vmONcvfMB9/wm6/PpcdX3+OW/Xzq+brw2kTxj01yReT/MKa5dcnuW2j8Uu3pSHJBUluHmPctbJgjHEoyU1JLpww9ktJ3r9q7MNJ3pfkvKp64vZPlyWy5XVnjHHvOsv+Ksm9Sb5+m+fJclnkPSdJUlXfl9mWqdfvyAxZVousOy9Msi/Jm3ZsdiyzRdadJ8yv71+z/LOZxWht1yRZTmOML29x6HmZrT/vWbP8PUmeudEu2csYDWcnuX2d5Qcze4PdaOyhMcZD64x9Qmabczh2LbLuPEJVnZVZlf/5gvNiuS203lTV3iRvTvLTY4zD2zw3ltsi684L5tdPqqqbq+pLVfWZqnpLVX3lts6SZbTIuvPhJJ9I8stVta+qvqqqzs1s68XbxxgPbu9UOYacndmWhrvWLD84v27XvWWMhpMy20drrcNJ9i4wduV2jl2LrDv/RFXtSfL2zLY0vHvxqbHEFl1v3pjkziS/tY1z4rFhkXXn6+bX709yXZJvT/Irme1q8NvbNUGW1pbXnTHGFzKLzpVd3D6X2e4lv5vkx7d3mhxjTkry2THfJ2mVSX8n79mRKS1u7YtJpm1uqwXGcmzYrv/+b0vyvCTfNcZY742dY8uW1puq+tYkP5jkOeu8CfP4sNX3nJUP7d4zxrh0/vNHqur4JG+oqn1jjDu2ZYYsq62+7zwps9h8amYHUN+T5JszOwHMw0l+dBvnyLFlob+TlzEajmT90tmb9at8tcNJ1jtd2d5Vt3PsWmTd+X+q6peS/HCSi8YY123T3Fhei6w378hsS9RfV9WT58v2JDl+/u/PjzG+uG0zZdkssu78/fz6D9csvy6zA1qfnUQ0HLsWWXdemdkxMWeOMT45X/ZHVXVfkndW1dvHGLdu20w5lhxOsreqas0HXZP+Tl7G3ZMOZrbP1Vr7svEb6MEkp89PZbZ27D/kkftwcWxZZN1JklTVJZmdbvU1Y4yrtnFuLK9F1puzkvxIZr/kVy7PT3LO/Gef+B3bFv19lTzyU7+VT/y2eqAjjw2LrDvPTHJkVTCs+LP59VkLzo1j18HMTvH8jWuWrxzL0K57yxgN1yY5Z37O8yTJ/Asrnj+/baOxX5Hk36wauyfJ9ya5zid+x7xF1p1U1U8kuSLJJWOMt+7QHFk+i6w3L1rncmtmBzi+KMnV2z9dlsgi687vZ3ZA4vlrlp83v75le6bIklpk3fnbzD4tXntyl2+ZX//NNs2RY88fZPYh+vevWf4DSW6fn8HrUdWy7YY7/9KSW5N8PsnPZPYpzOVJvjrJs8YYD8zvd2qST2Z2Dv3LVo1/X2Zvuj+V5FBmn/R9d5LnjTE+dhRfCkfZIutOVb0ss4MPP5TkF9Y89P32LT52Lfqes87jfSTJnjHGCx7tPhwbtuH31c9l9uVcv5LZF33tT/JzSd4/xnjF0XslHG0L/r46LcltmcXDL2Z2TMP+zNalO5N88wKn5OQxoqq+Z/7jv8hsi/ePZXbylnvHGB+d3+fhJFeOMV65atwbkrw2yX9K8rHMPlh/dZILxxi/0z3n0h3TMMZ4cH7qsDcnuSqzTbXXJ3ntyv9Ec5XZt2au3VryQ5n9T3RFkidn9j/l+YLh2LfgunP+fPn5eeQnfx/NbP9RjkHb8J7D49Q2rDuXZXbmmx9L8pNJPp3Z2bgu3+Gps8sWWXfGGHdX1TmZfavvFUmekuRTSd6Z5BcFw+PGB9b8+zfm16v/Zjk+j/yG+UuSPJDZKXq/NrMvQH7pRsGQLOGWBgAAYLn4xAwAAGiJBgAAoCUaAACAlmgAAABaogEAAGiJBgAAoCUaAACAlmgAAABaogEAAGj9X1QbBHO2JTk2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb455f654e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos el score del algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score del MLP: 0.8301376582376154\n"
     ]
    }
   ],
   "source": [
    "print(f\"Score del MLP: {mlp.score(X_test, y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
